---
title: "Replication of Study 1 by Caroline Charpentier (2016, Psychological Science)"
author: "Michael Ko (mlko53 [at] stanford [dot] edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

[No abstract is needed.]  Each replication project will have a straightforward, no frills report of the study and results.  These reports will be publicly available as supplementary material for the aggregate report(s) of the project as a whole.  Also, to maximize project integrity, the intro and methods will be written and critiqued in advance of data collection.  Introductions can be just 1-2 paragraphs clarifying the main idea of the original study, the target finding for replication, and any other essential information.  It will NOT have a literature review -- that is in the original publication. You can write both the introduction and the methods in past tense.  


##Methods

###Power Analysis

Charpentier used a paired t test to compare the weights of losing coeficients to weights of wining coeficients. This test was to see of one was significantly larger than the other in the choice models.

Original paper reports

> "We determined that a sample size
of 59 participants would achieve 85% power to detect an
effect size of 0.401 with an alpha of .05."

Using the effect size found in the original paper (d = 0.392) with an alpha of .05, 53 participants will achieve 80% power.


###Planned Sample

For the sake of feasibility in collecting data. I plan to use 30 participants with a shorter version of their experiment. Although this significanlty reduces the sample of the experiment, their main analysis does not rely on comparing the weights of losing and wining to each other, but rather, the predictive power of the models itself, which don't depend on sample size as much as t tests do.

###Materials

Basic geometric shapes were used for each stimulus in a trial. Each trial had a different geometric shape to ensure that associations of monetary outcomes and the shapes did not carry throughout trials.

###Procedure	

**Feeling Task**

In the feelings task, participants completed
four blocks of 40 to 48 trials each, in which they
reported either expected (Fig. 1a) or experienced (Fig.
1b) feelings associated with a range of wins and losses
(between £0.2 and £12) or with no change in monetary
amount (£0). At the beginning of each trial, participants
were told how much was at stake and whether it was a
win trial (e.g., "If you choose the GOOD picture, you
will: WIN £10") or a loss trial (e.g., "If you choose the
BAD picture, you will: LOSE £10"). On each trial, their
task was to make a simple arbitrary choice between two
different geometrical shapes. Participants were told that
one stimulus was randomly associated with a gain or loss
(between £0.2 and £12) and the other stimulus with no
gain and no loss (£0). Each stimulus was presented only
once across the entire task so there was no way for participants
to learn which stimulus was associated with a
better outcome. The probability of sampling each amount
was controlled to ensure that each gain and each loss
from the range was sampled twice in each block: In one
instance, the outcome was the amount at stake (win/loss),
and in the other, the outcome was £0 (no win/no loss).

In two of the four blocks (counterbalanced order),
participants reported their expected feelings prior to
choosing between the two stimuli (Fig. 1a), and in the
other two blocks, they reported their experienced feelings
after choosing between the two stimuli (Fig. 1b).
Participants reported their expected feelings by answering
one of four questions asking how they would feel if
they "win," "lose," "don't win," or "don't lose" (the order
of win/lose and don't-win/don't-lose questions was
counterbalanced across trials). In experienced-feelings
blocks, participants answered the question "How do you
feel now?" All feelings were rated using a subjective rating
scale ranging from extremely unhappy to extremely
happy. Expected and experienced feelings were collected
in different blocks to ensure participants did not simply
remember and repeat the same rating. The choice
between the two geometrical shapes was arbitrary and
implemented simply in order to have participants actively
involved with the outcomes.

**Gambling Task**

Participants also completed a probabilistic-
choice task (Fig. 1c) in which they made 288 to
322 choices between a risky 50-50 gamble and a sure
option. Importantly, all the amounts used in the gambling
task were the same as those used in the feelings
task (between £0.2 and £12), so feelings associated with
these outcomes could be combined to predict gambling
choice. There were three gamble types: mixed (participants
had to choose between a gamble with a 50%
chance of a gain and 50% chance of a loss, or a sure
option of £0), gain only (participants had to choose
between a gamble with a 50% chance of a high gain and
a 50% chance of £0, or a sure, smaller gain), and loss
only (participants had to choose between a gamble with
50% chance of a high loss and 50% chance of £0, or a
sure, smaller loss). According to prospect theory, these
three types of choices are essential to estimate loss aversion,
risk preference for gains, and risk preference for
losses, respectively.

###Analysis Plan

**Feeling Function Models**

Model subjective feelings from three different baselines: difference from the midpoint
of the rating scale, difference from the rating
reported on the previous trial (for experienced feelings
only), and difference from the corresponding zero outcome.

10 different models were fit for each feeling block, expected and experienced. Best model in each feeling block was determiend by using BIC as model selection criterion and 100 split half analysis. 

**Gambling Choice Models**

Each choice model used logistic regression on three predictors, a win value, loss value and sure value. Every choice model has a different transformations from the objective monetary values. Some of these objective to subjective value transformations were models from the best feeling function models. 7 different choice models were fitted. Best model was deteremined by using BIC as model selection criterion and 100 split half analysis. 

Weights associated with win and weights associated with loss are compared. From their key choice model of interest, these weights are extracted, standardized and then compared using paired sample t test and repeated measures ANOVA.

###Differences from Original Study

I'm using a smaller sample size in order to fit the contraints of the class budget. Furthermore, I'm using less trials in each feeling block. Instead of 2 blocks of 48 trials for each expected and experienced blocks, I'm only using 1 block of 48 trials. Gambling trial length remains the same.

### Methods Addendum (Post Data Collection)

Although accuracy is typically not a criteria for model selection, I think graphing and displaying the mean accuracy of each model is nice so that readers would have a intuitive idea of the predictive power of each model.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or none.


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions
set.seed(456) # so that cross val is the same for reproducibility
library(ggplot2)
library(tidyr)
library(dplyr)
library(jsonlite)

####Import data

#init params
nparticipants <- 2
n.iter <- 10 #CHANGE THIS TO 100 LATER

d <- fromJSON('../expt/pilot_data/pilot1.json')
d$stimulus <- NULL
d$id <- 1

temp_d <- fromJSON('../expt/pilot_data/pilot2.json')
temp_d$stimulus <- NULL
temp_d$id <- 2

d <- rbind(d, temp_d)

d <- d %>% filter(!is.na(feel_trial_type) | !is.na(gamble_trial_type))


#### Prepare data for analysis - create columns etc.

# transform 1-9 likert subjective response to -4 - 4 so that neutral is 0
d$response <- as.integer(d$response)
d$response <- d$response - 5


#### Data exclusion / filtering

# split the data into the blocks
feel_expect <- d %>% 
        filter(feel_trial_type != "now" & feel_trial_type != "") %>%
        select(feel_trial_type, value, response, id)

feel_experience <- d %>% 
        filter(feel_trial_type == "now") %>%
        select(feel_trial_type, value, response, id)

gamble_block <- d %>% 
        filter(!is.na(gamble_trial_type)) %>%
        select(gamble_trial_type, win, lose, sure, key_press, gamble_side, id)

gamble = logical(0)
for(i in 1:length(gamble_block$gamble_side)){
        if(gamble_block$gamble_side[i] == ""){
                gamble <- c(gamble, NA)
        } else{
                if(gamble_block$gamble_side[i] == "R" & gamble_block$key_press[i] == 80){
                        gamble <- c(gamble, TRUE)
                } else if(gamble_block$gamble_side[i] == "L" & gamble_block$key_press[i] == 81){
                        gamble <- c(gamble, TRUE)
                } else{
                        gamble <- c(gamble, FALSE)
                }
        }
}

gamble_block$gamble <- gamble

```

**Helper Functions**

```{r include=F}

# splits dataframe in half randomly
split_half <- function(d){
        val_length <- round(nrow(d) / 2)
        val_indices <- sample(seq_len(nrow(d)), size = val_length)
        return(d[val_indices, ])
}

# calculate BIC total for feel models

feel_BIC <- function(num){
        vector <- double(20)
        model_names <- character(20)

        for(i in 1:10){
                model_names[i] <- paste0(paste0("feel_expect_mod", i), ".fit")
        }
        
        for(i in 11:20){
                model_names[i] <- paste0(paste0("feel_experience_mod", i - 10), ".fit")
        }
        
        for(i in 1:num){
                for(j in 1:20){
                        model <- paste0(paste0(paste0(model_names[j], "[["), i), "]]") ## make feel_expect_mod j .fit[[ i ]]
                        vector[j] <- vector[j] + BIC(eval(parse(text = model)))
                }
        }
        return(vector)
}

# log transformation for choice model
log0 <- function(x){
        
        if(length(x) == 1){
        
                if(x == 0){
                        ans = 0
                } else if(x < 0){
                        ans = -log1p(-x)
                } else{
                        ans = log1p(x)
                }
                return(ans)
        } else{
                return(sapply(x, FUN = log0))
        }
}

# returns a list or predicted values; win == 1, lost == 2, sure == 3
transform_predict <- function(win, lose, sure, model){
        twin <- predict(model, data.frame(value = win))
        tlose <- predict(model, data.frame(value = lose))
        tsure <- predict(model, data.frame(value = sure))
        return(list(twin, tlose, tsure))
}

gamble_log_fit <- function(d, model){
        params <- transform_predict(d$win, d$lose, d$sure, model)
        return(glm(d$gamble ~ params[[1]] + params[[2]] + params[[3]] + 0, family = binomial(link = "logit")))
}

# calculate BIC total for choice models
choice_BIC <- function(num){
        vector <- double(7)
        for(i in 1:10){
                model_names[i] <- paste0(paste0("choice_mod", i), ".fit")
        }
        
        for(i in 1:num){
                for(j in 1:7){
                        model <- paste0(paste0(paste0(model_names[j], "[["), i), "]]")
                        vector[j] <- vector[j] + BIC(eval(parse(text = model)))
                }
        }
        return(vector)
}
```

**Feeling Functions**

```{r include=F}

mod1 <- response ~ b * value
mod2 <- response ~ ifelse(value > 0, bgain * value, bloss * value)
mod3 <- response ~ ifelse(value > 0, b * abs(value) ^ p , -b * abs(value) ^ p)
mod4 <- response ~ ifelse(value > 0, bgain * abs(value) ^ p, -bloss * abs(value) ^ p)
mod5 <- response ~ ifelse(value > 0, b * abs(value) ^ pgain, -b * abs(value) ^ ploss)                            ## 5 has problems converging               
mod6 <- response ~ ifelse(value > 0, bgain * abs(value) ^ pgain, -bloss * abs(value) ^ ploss)                    ## 6 has problems converging
mod7 <- response ~ ifelse(value > 0, b * value + e, b * value - e)                                      
mod8 <- response ~ ifelse(value > 0, bgain * value + e, bloss * value - e)                              
mod9 <- response ~ ifelse(value > 0, b * value + egain, b * value - eloss)
mod10 <- response ~ ifelse(value > 0, bgain * value + egain, bloss * value - eloss)

## Here begins the worst code that I've ever written in my entire life

feel_fit <- function(split = TRUE, num){
        
        ## init empty lists of models
        feel_expect_mod1.fit <- list()
        feel_expect_mod2.fit <- list()
        feel_expect_mod3.fit <- list()
        feel_expect_mod4.fit <- list()
        feel_expect_mod5.fit <- list()
        feel_expect_mod6.fit <- list()
        feel_expect_mod7.fit <- list()
        feel_expect_mod8.fit <- list()
        feel_expect_mod9.fit <- list()
        feel_expect_mod10.fit <- list()
        
        feel_experience_mod1.fit <- list()
        feel_experience_mod2.fit <- list()
        feel_experience_mod3.fit <- list()
        feel_experience_mod4.fit <- list()
        feel_experience_mod5.fit <- list()
        feel_experience_mod6.fit <- list()
        feel_experience_mod7.fit <- list()
        feel_experience_mod8.fit <- list()
        feel_experience_mod9.fit <- list()
        feel_experience_mod10.fit <- list()

        
        ## fit each model to each participant
        for(i in 1:num){
                
                temp_feel_expect <- feel_expect %>% filter(id == i)
                
                temp_feel_experience <- feel_experience %>% filter(id == i)
                
                #only half split when bootstrapping
                if(split == TRUE){
                        temp_feel_expect <- split_half(temp_feel_expect)
                        temp_feel_experience <- split_half(temp_feel_experience)
                }
                
                feel_expect_mod1.fit <- c(feel_expect_mod1.fit, 
                                          list(nls(data = temp_feel_expect, mod1, start = c(b = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                
                feel_expect_mod2.fit <- c(feel_expect_mod2.fit, 
                                          list(nls(data = temp_feel_expect, mod2, start = c(bgain = .5, bloss = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                
                feel_expect_mod3.fit <- c(feel_expect_mod3.fit, 
                                          list(nls(data = temp_feel_expect, mod3, start = c(b = .5, p = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod4.fit <- c(feel_expect_mod4.fit, 
                                          list(nls(data = temp_feel_expect, mod4, start = c(bgain = .5, bloss = .5, p = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod5.fit <- c(feel_expect_mod5.fit, 
                                          list(nls(data = temp_feel_expect, mod5, start = c(b = .5, pgain = .5, ploss = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod6.fit <- c(feel_expect_mod6.fit, 
                                          list(nls(data = temp_feel_expect, mod6, start = c(bgain = .5, bloss = .5, pgain = .5, ploss = .5),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod7.fit <- c(feel_expect_mod7.fit, 
                                          list(nls(data = temp_feel_expect, mod7, start = c(b = .5, e = .1),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod8.fit <- c(feel_expect_mod8.fit, 
                                          list(nls(data = temp_feel_expect, mod8, start = c(bgain = .5, bloss = .5, e = .1),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod9.fit <- c(feel_expect_mod9.fit, 
                                          list(nls(data = temp_feel_expect, mod9, start = c(b = 1, egain = .1, eloss = .1),
                                                   control = list(maxiter = 50000, minFactor=1/2000))))
                feel_expect_mod10.fit <- c(feel_expect_mod10.fit, 
                                           list(nls(data = temp_feel_expect, mod10, start = c(bgain = 1, bloss = 1, egain = .1, eloss = .1),
                                                    control = list(maxiter = 50000, minFactor=1/2000))))
              
                
                feel_experience_mod1.fit <- c(feel_experience_mod1.fit, 
                                              list(nls(data = temp_feel_experience, mod1, start = c(b = 1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod2.fit <- c(feel_experience_mod2.fit, 
                                              list(nls(data = temp_feel_experience, mod2, start = c(bgain = 1, bloss = 1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod3.fit <- c(feel_experience_mod3.fit, 
                                              list(nls(data = temp_feel_experience, mod3, start = c(b = 1, p = 1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod4.fit <- c(feel_experience_mod4.fit, 
                                              list(nls(data = temp_feel_experience, mod4, start = c(bgain = .5, bloss = .5, p = .5),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod5.fit <- c(feel_experience_mod5.fit, 
                                              list(nls(data = temp_feel_experience, mod5, start = c(b = 1, pgain = 1, ploss = 1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod6.fit <- c(feel_experience_mod6.fit, 
                                              list(nls(data = temp_feel_experience, mod6, start = c(bgain = 1, bloss = 1, pgain = 1, ploss = 1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod7.fit <- c(feel_experience_mod7.fit, 
                                              list(nls(data = temp_feel_experience, mod7, start = c(b = 1, e = .1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod8.fit <- c(feel_experience_mod8.fit, 
                                              list(nls(data = temp_feel_experience, mod8, start = c(bgain = 1, bloss = 1, e = .1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod9.fit <- c(feel_experience_mod9.fit, 
                                              list(nls(data = temp_feel_experience, mod9, start = c(b = 1, egain = .1, eloss = .1),
                                                       control = list(maxiter = 50000, minFactor=1/2000))))
                feel_experience_mod10.fit <- c(feel_experience_mod10.fit, 
                                               list(nls(data = temp_feel_experience, mod10, start = c(bgain = 1, bloss = 1, egain = .1, eloss = .1),
                                                        control = list(maxiter = 50000, minFactor=1/2000))))
        }
        
        assign("feel_expect_mod1.fit", feel_expect_mod1.fit, envir = .GlobalEnv)
        assign("feel_expect_mod2.fit", feel_expect_mod2.fit, envir = .GlobalEnv)
        assign("feel_expect_mod3.fit", feel_expect_mod3.fit, envir = .GlobalEnv)
        assign("feel_expect_mod4.fit", feel_expect_mod4.fit, envir = .GlobalEnv)
        assign("feel_expect_mod5.fit", feel_expect_mod5.fit, envir = .GlobalEnv)
        assign("feel_expect_mod6.fit", feel_expect_mod6.fit, envir = .GlobalEnv)
        assign("feel_expect_mod7.fit", feel_expect_mod7.fit, envir = .GlobalEnv)
        assign("feel_expect_mod8.fit", feel_expect_mod8.fit, envir = .GlobalEnv)
        assign("feel_expect_mod9.fit", feel_expect_mod9.fit, envir = .GlobalEnv)
        assign("feel_expect_mod10.fit", feel_expect_mod10.fit, envir = .GlobalEnv)
        
        assign("feel_experience_mod1.fit", feel_experience_mod1.fit, envir = .GlobalEnv)
        assign("feel_experience_mod2.fit", feel_experience_mod2.fit, envir = .GlobalEnv)
        assign("feel_experience_mod3.fit", feel_experience_mod3.fit, envir = .GlobalEnv)
        assign("feel_experience_mod4.fit", feel_experience_mod4.fit, envir = .GlobalEnv)
        assign("feel_experience_mod5.fit", feel_experience_mod5.fit, envir = .GlobalEnv)
        assign("feel_experience_mod6.fit", feel_experience_mod6.fit, envir = .GlobalEnv)
        assign("feel_experience_mod7.fit", feel_experience_mod7.fit, envir = .GlobalEnv)
        assign("feel_experience_mod8.fit", feel_experience_mod8.fit, envir = .GlobalEnv)
        assign("feel_experience_mod9.fit", feel_experience_mod9.fit, envir = .GlobalEnv)
        assign("feel_experience_mod10.fit", feel_experience_mod10.fit, envir = .GlobalEnv)
        

        
}

# use nls to fit models
# use BIC on fitted models to return BI
```

**Choice Functions**

```{r include=F}

choice_fit <- function(split = TRUE, num){
        
        choice_mod1.fit <- list()
        choice_mod2.fit <- list()
        choice_mod3.fit <- list()
        choice_mod4.fit <- list()
        choice_mod5.fit <- list()
        choice_mod6.fit <- list()
        choice_mod7.fit <- list()
        
        for(i in 1:num){
                temp_gamble_block <- gamble_block %>% filter(id == i)
                if(split == TRUE){
                        temp_gamble_block <- split_half(temp_gamble_block)
                }
                
                choice_mod1.fit <- c(choice_mod1.fit, list(gamble_log_fit(gamble_block, feel_expect_mod3.fit[[i]])))
                choice_mod2.fit <- c(choice_mod2.fit, list(gamble_log_fit(gamble_block, feel_experience_mod3.fit[[i]])))
                choice_mod3.fit <- c(choice_mod3.fit, list(glm(data = temp_gamble_block, gamble ~ 0 + win + lose + sure, family = binomial)))
                choice_mod4.fit <- c(choice_mod4.fit, list(glm(data = temp_gamble_block, gamble ~ 0 + log0(win) + log0(lose) + log0(sure), family = binomial)))
                choice_mod5.fit <- c(choice_mod5.fit, list(nls(data = temp_gamble_block, gamble ~ 1 / (1 + exp(1) ^ -(u * (0.5 * win + 0.5 * lamda * lose))), 
                                                               start = c(u = 1, lamda = 1),
                                                               control = list(maxiter = 50000, minFactor=1/2000))))
                choice_mod6.fit <- c(choice_mod6.fit, list(nls(data = temp_gamble_block, gamble ~ 1 / (1 + exp(1) ^ -(u * (0.5 * (abs(win) ^ gamma) - 0.5 * (abs(lose) ^ gamma)))),
                                                               start = c(u = 1, gamma = .5),
                                                               control = list(maxiter = 50000, minFactor=1/2000))))
                choice_mod7.fit <- c(choice_mod7.fit, list(nls(data = temp_gamble_block, gamble ~ 1 / (1 + exp(1) ^ -(u * (0.5 * (abs(win) ^ gamma) - 0.5 * lamda * (abs(lose) ^ gamma)))),
                                                               start = c(u = 1, gamma = .5, lamda = 1),
                                                               control = list(maxiter = 50000, minFactor=1/2000))))
                
        }
        
        assign("choice_mod1.fit", choice_mod1.fit, envir = .GlobalEnv)
        assign("choice_mod2.fit", choice_mod2.fit, envir = .GlobalEnv)
        assign("choice_mod3.fit", choice_mod3.fit, envir = .GlobalEnv)
        assign("choice_mod4.fit", choice_mod4.fit, envir = .GlobalEnv)
        assign("choice_mod5.fit", choice_mod5.fit, envir = .GlobalEnv)
        assign("choice_mod6.fit", choice_mod6.fit, envir = .GlobalEnv)
        assign("choice_mod7.fit", choice_mod7.fit, envir = .GlobalEnv)
}

```


### Confirmatory analysis

**Feeling Models**

```{r fitting_feeling_model}

## init feeling functions dataframe
feeling_models <- data.frame(matrix(ncol = 20, nrow = n.iter))

model_names <- character(20)
for(i in 1:10){
        model_names[i] <- paste0("feel_expect_mod", i)
}
        
for(i in 11:20){
        model_names[i] <- paste0("feel_experience_mod", i - 10)
}

colnames(feeling_models) <- model_names

## compute 100 boostraps
for(i in 1:n.iter){
        feel_fit(split = TRUE, nparticipants)
        feeling_models[i, ] <- feel_BIC(nparticipants)
}

```

```{r plot_feeling_models}
ggplot(feeling_models %>% 
               select(1:10) %>% 
               gather("model", "BIC", 1:10) %>%
               separate(model, sep="_", into= c("first", "second", "model")), aes(x = model, y = BIC)) + 
        stat_summary(fun.y = "mean", geom="bar") +
        coord_cartesian(ylim = c(300, 400))

ggplot(feeling_models %>% 
               select(11:20) %>% 
               gather("model", "BIC", 1:10) %>%
               separate(model, sep="_", into= c("first", "second", "model")), aes(x = model, y = BIC)) + 
        stat_summary(fun.y = "mean", geom="bar") 
```

**Choice Models**

```{r fitting_choice_model}

#init choice model array
choice_models <- data.frame(matrix(ncol = 7, nrow = n.iter))

model_names <- character(7)

for(i in 1:7){
        model_names[i] <- paste0(paste0("choice_mod", i), ".fit")
}

colnames(choice_models) <- model_names

#start fitting
feel_fit(split = FALSE, num = nparticipants) # fit feel model with all the data

########STILL IN THE PROCESS OF FIGURING CHOICE MODELS OUT ############

##PROBLEM: Model 5, 6, and 7 is highly unstable. R is having trouble converging. It might be the way that I'm writing the formulas. Worse comes to case, I exclude these models from the analysis. This isnt' a bad idea since if these models aren't converging in the first place, they shouldn't be good models.

#for(i in 1:n.iter){
#        
#        choice_fit(split = FALSE, nparticipants) # fit choice models split half
#        choice_models[i, ] <- choice_BIC(nparticipants)
#}

```

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
